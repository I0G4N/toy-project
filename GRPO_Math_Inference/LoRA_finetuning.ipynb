{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cc1dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logan/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/logan/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 00:44:24,633 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/logan/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 00:44:26,232 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5553fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fda8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def create_prompt_formats(sample):\n",
    "    INTRO = \"Instruct: Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "    INSTRUCTION_KEY = 'Input: According to the following questions, please give detailed reasoning steps and answers in the following format: \\n<reasoning>\\n{reasoning}\\n</reasoning>\\n<answer>\\n{answer}\\n</answer>'\n",
    "    RESPONSE_KEY = 'Output:'\n",
    "\n",
    "    blurb = f\"{INTRO}\"\n",
    "    instruction = f\"{INSTRUCTION_KEY}\"\n",
    "    input_context = f\"{sample['question']}\" if sample['question'] else None\n",
    "\n",
    "    reasoning, answer = [p.strip() for p in sample['answer'].split('####')]\n",
    "    response = f\"{RESPONSE_KEY}\\n<reasoning>\\n{reasoning}\\n</reasoning>\\n<answer>\\n{answer}\\n</answer>\"\n",
    "\n",
    "    parts = [part for part in [blurb, instruction, input_context, response] if part]\n",
    "    formatted_prompt = \"\\n\\n\".join(parts)\n",
    "\n",
    "    sample[\"formatted_prompt\"] = formatted_prompt\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def preprocess_batch(batch, tokenizer):\n",
    "    return tokenizer(batch[\"formatted_prompt\"], truncation=True)\n",
    "\n",
    "def preprocess_dataset(tokenizer, dataset):\n",
    "    dataset = dataset.map(create_prompt_formats)\n",
    "\n",
    "    _preprocessing_function = partial(preprocess_batch, tokenizer=tokenizer)\n",
    "    dataset = dataset.map(\n",
    "        _preprocessing_function,\n",
    "        batched=True,\n",
    "        remove_columns=['question', 'answer']\n",
    "    )\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab885905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['formatted_prompt', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 7473\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['formatted_prompt', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 1319\n",
       " }))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = preprocess_dataset(tokenizer, data['train'])\n",
    "test_dataset = preprocess_dataset(tokenizer, data['test'])\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045c3c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlogan-zh-cai\u001b[0m (\u001b[33mlogan-cai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/logan/working/toy-project/GRPO_Math_Inference/wandb/run-20251001_004435-ltjjqe3r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/logan-cai/LongCoT_Math_Inference/runs/ltjjqe3r' target=\"_blank\">earnest-oath-10</a></strong> to <a href='https://wandb.ai/logan-cai/LongCoT_Math_Inference' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/logan-cai/LongCoT_Math_Inference' target=\"_blank\">https://wandb.ai/logan-cai/LongCoT_Math_Inference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/logan-cai/LongCoT_Math_Inference/runs/ltjjqe3r' target=\"_blank\">https://wandb.ai/logan-cai/LongCoT_Math_Inference/runs/ltjjqe3r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/logan-cai/LongCoT_Math_Inference/runs/ltjjqe3r?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7495be29b5e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"LongCoT_Math_Inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d90300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1869' max='1869' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1869/1869 35:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.103800</td>\n",
       "      <td>1.304907</td>\n",
       "      <td>1.220567</td>\n",
       "      <td>52212.000000</td>\n",
       "      <td>0.693677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.959633</td>\n",
       "      <td>0.530438</td>\n",
       "      <td>103026.000000</td>\n",
       "      <td>0.806221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.891864</td>\n",
       "      <td>0.531519</td>\n",
       "      <td>154464.000000</td>\n",
       "      <td>0.812313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.879994</td>\n",
       "      <td>0.517749</td>\n",
       "      <td>206532.000000</td>\n",
       "      <td>0.814471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.907150</td>\n",
       "      <td>0.489435</td>\n",
       "      <td>258985.000000</td>\n",
       "      <td>0.814356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.371700</td>\n",
       "      <td>0.888174</td>\n",
       "      <td>0.505080</td>\n",
       "      <td>308837.000000</td>\n",
       "      <td>0.815616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.884377</td>\n",
       "      <td>0.501222</td>\n",
       "      <td>360783.000000</td>\n",
       "      <td>0.816004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.888815</td>\n",
       "      <td>0.498862</td>\n",
       "      <td>412421.000000</td>\n",
       "      <td>0.816821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>0.504984</td>\n",
       "      <td>463493.000000</td>\n",
       "      <td>0.816444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>0.878726</td>\n",
       "      <td>0.496081</td>\n",
       "      <td>515863.000000</td>\n",
       "      <td>0.816960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.501057</td>\n",
       "      <td>568810.000000</td>\n",
       "      <td>0.817078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.881186</td>\n",
       "      <td>0.498908</td>\n",
       "      <td>619254.000000</td>\n",
       "      <td>0.816860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.900629</td>\n",
       "      <td>0.486969</td>\n",
       "      <td>670850.000000</td>\n",
       "      <td>0.816618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.868574</td>\n",
       "      <td>0.498426</td>\n",
       "      <td>723007.000000</td>\n",
       "      <td>0.818037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.288200</td>\n",
       "      <td>0.895390</td>\n",
       "      <td>0.485577</td>\n",
       "      <td>774273.000000</td>\n",
       "      <td>0.816940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.890067</td>\n",
       "      <td>0.491933</td>\n",
       "      <td>826120.000000</td>\n",
       "      <td>0.816950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.881450</td>\n",
       "      <td>0.497352</td>\n",
       "      <td>879038.000000</td>\n",
       "      <td>0.817584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.895035</td>\n",
       "      <td>0.484356</td>\n",
       "      <td>929696.000000</td>\n",
       "      <td>0.817301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>0.486214</td>\n",
       "      <td>982343.000000</td>\n",
       "      <td>0.817552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>0.878687</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>1034812.000000</td>\n",
       "      <td>0.817507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.496135</td>\n",
       "      <td>1087343.000000</td>\n",
       "      <td>0.817865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>0.887184</td>\n",
       "      <td>0.491752</td>\n",
       "      <td>1137400.000000</td>\n",
       "      <td>0.817807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.888173</td>\n",
       "      <td>0.486992</td>\n",
       "      <td>1188668.000000</td>\n",
       "      <td>0.817805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.886109</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>1241561.000000</td>\n",
       "      <td>0.817784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>1292798.000000</td>\n",
       "      <td>0.818103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.883183</td>\n",
       "      <td>0.489714</td>\n",
       "      <td>1343320.000000</td>\n",
       "      <td>0.817899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.891049</td>\n",
       "      <td>0.484367</td>\n",
       "      <td>1395336.000000</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.886642</td>\n",
       "      <td>0.486483</td>\n",
       "      <td>1445964.000000</td>\n",
       "      <td>0.818079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.882652</td>\n",
       "      <td>0.489831</td>\n",
       "      <td>1498253.000000</td>\n",
       "      <td>0.818245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.882724</td>\n",
       "      <td>0.491338</td>\n",
       "      <td>1552387.000000</td>\n",
       "      <td>0.818054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>0.880883</td>\n",
       "      <td>0.492204</td>\n",
       "      <td>1605098.000000</td>\n",
       "      <td>0.818131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.886468</td>\n",
       "      <td>0.488081</td>\n",
       "      <td>1656137.000000</td>\n",
       "      <td>0.817972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.885858</td>\n",
       "      <td>0.488324</td>\n",
       "      <td>1708605.000000</td>\n",
       "      <td>0.818085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.884367</td>\n",
       "      <td>0.489520</td>\n",
       "      <td>1761228.000000</td>\n",
       "      <td>0.818134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.883934</td>\n",
       "      <td>0.490130</td>\n",
       "      <td>1812477.000000</td>\n",
       "      <td>0.818211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.883877</td>\n",
       "      <td>0.490343</td>\n",
       "      <td>1865914.000000</td>\n",
       "      <td>0.818025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.884785</td>\n",
       "      <td>0.489539</td>\n",
       "      <td>1918794.000000</td>\n",
       "      <td>0.818065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import LoraConfig\n",
    "from trl.trainer import SFTTrainer, SFTConfig\n",
    "\n",
    "output_dir = 'outputs/Long-CoT-Math-Inference-Finetuning'\n",
    "run_name = 'Qwen2.5-0.5B-Long-CoT-gsm8k'\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    bias='none',\n",
    "    lora_dropout=0.01,\n",
    "    task_type='CAUSAL_LM'\n",
    ")\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    run_name=run_name,\n",
    "    learning_rate=1e-4,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.99,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    logging_steps=1,\n",
    "    bf16=True,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_length=512,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=100,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_checkpointing=True,\n",
    "    overwrite_output_dir=True,\n",
    "    report_to='wandb',\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=sft_config\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1787974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/logan/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 02:02:24,730 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/logan/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 02:02:26,908 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "from numpy import dtype\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    './outputs/Long-CoT-Math-Inference-Finetuning/checkpoint-1869',\n",
    "    dtype=torch.bfloat16,\n",
    "    is_trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05b0dafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "Input: According to the following questions, please give detailed reasoning steps and answers in the following format: \n",
      "<reasoning>\n",
      "{reasoning}\n",
      "</reasoning>\n",
      "<answer>\n",
      "{answer}\n",
      "</answer>\n",
      "\n",
      "Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "\n",
      "Output:\n",
      "<reasoning>\n",
      "She eats 3 + 4 = <<3+4=7>>7 muffins every day.\n",
      "So she sells 16 - 7 = <<16-7=9>>9 eggs every day.\n",
      "Thus, she makes 9 * 2 = $<<9*2=18>>18 every day from selling eggs.\n",
      "</reasoning>\n",
      "<answer>\n",
      "18\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Instruct: Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\nInput: According to the following questions, please give detailed reasoning steps and answers in the following format: \\n<reasoning>\\n{reasoning}\\n</reasoning>\\n<answer>\\n{answer}\\n</answer>\\n\\nJanet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\\n\\nOutput:\\n\"\n",
    "\n",
    "toks = tokenizer(prompt, return_tensors=\"pt\")\n",
    "res = ft_model.generate(**toks.to(\"cuda\"),\n",
    "                        max_new_tokens=512).to(\"cpu\")\n",
    "res_a = tokenizer.batch_decode(res, skip_special_tokens=True)\n",
    "print(res_a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5572a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "Input: According to the following questions, please give detailed reasoning steps and answers in the following format: \n",
      "<reasoning>\n",
      "{reasoning}\n",
      "</reasoning>\n",
      "<answer>\n",
      "{answer}\n",
      "</answer>\n",
      "\n",
      "Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "\n",
      "Output:\n",
      "<reasoning>\n",
      "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
      "</reasoning>\n",
      "<answer>\n",
      "18\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0]['formatted_prompt'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
